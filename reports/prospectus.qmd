---
title: "Prospectus"
date-modified: today
date-format: medium
author:
  - name: "Elaine Lu"
    email: lul21@wfu.edu
    affiliation: "WFU-Lin-380"
abstract: |
  Social media platforms, depending on their targeted users and fucntions, now have develop various genres for different types of posts, such as instagram posts, discussion posts on Quora, or short fictions fans posted to share and interact with each other in AO3. Some genres are similar to traditional writing genres, while some others do not. To maintain consistency in text analysis, online fictions, including fan fictions, will be employed to compare and contrast with traditional novels, fictions, and academic writing. This study aims to conduct a sentiment analysis across platforms, to compare and contrast the dominant sentiment in different platforms, and potentiall to analyze the reason behind the phenomenon. 
  
keywords:
  - Sentimental Analysis
citation: true
bibliography: ../bibliography.bib
---

# Introduction

This study is about sentiment levels of expressions in relation to platforms, whether the posted expressions are mainly super positive, positive, negative, or super negative. Internet has become an indispensable part of people's life today, and different social media has different potential users. Twitter and Facebook often include a large spectrum of users, from seniors to teens, meanwhile, Instagram posts often are often targeted young audiences, etc. Yet, would different targeted users and potential audiences influence the sentiment level of the posts users post online? This is also what this project aims to find out.  

## Literature review

Balahur presents a method for sentiment analysis using Twitter data (tweets) as an example, taking into account their structure, length and specific language. The approach employed makes it easily extendible to other languages and makes it able to process tweets in near real time. The main contri- butions of this work are: a) the pre-processing of tweets to normalize the language and gener- alize the vocabulary employed to express sentiment; b) the use minimal linguistic process- ing, which makes the approach easily portable to other languages; c) the inclusion of higher order n-grams to spot modifications in the po- larity of the sentiment expressed; d) the use of simple heuristics to select features to be em- ployed; e) the application of supervised learn- ing using a simple Support Vector Machines linear classifier on a set of realistic data. Similar methods can be applied in analyzing data collected for this research @JRC82012.

The paper "OPINION EVENTS: TYPES AND OPINION MARKERS IN ENGLISH SOCIAL MEDIA DISCOURSE" by Barbara Lewandowska-Tomaszczyk investigates opinion events and opinion markers in English social media discourse. It explores various types of opinion events and identifies the linguistic markers used to express opinions in online discussions. The study employs a corpus-based approach to analyze social media data and identifies patterns in how opinions are expressed and shared on platforms like Twitter or Facebook. The paper provides insights into the structure and characteristics of opinion events in online discourse, shedding light on the role of language in shaping and disseminating opinions in the digital age @LewandowskaTomaszczyk2023.

Andreotta presents a mixed-methods approach for analyzing social media data that integrates computational and qualitative text analysis techniques. The framework proposed in the paper combines quantitative methods such as machine learning and natural language processing with qualitative methods like thematic analysis and discourse analysis. This comprehensive approach enables researchers to gain deeper insights into social media data by combining the strengths of both computational and qualitative approaches. The paper discusses the rationale behind using mixed methods, outlines the steps involved in the framework, and provides examples of how it can be applied in social media research. Overall, the paper contributes to the methodological toolkit for studying social media phenomena by offering a systematic and flexible approach that leverages the complementary strengths of computational and qualitative analysis methods @Andreotta2019. 

Despot discusses the current automatic detection mechanism of offensive language and its shortcomings and how current situation can be improved. This study argues that current difficulties in detecting implicit offence are exacerbated by multiple factors: (a) inadequate definitions of implicit and explicit offense; (b) an insufficient typology of implicit offence; and (c) a dearth of detailed analysis of implicitly offensive linguistic data. In this study, based on a qualitative analysis of an implicitly offensive dataset, a new typology of implicitly offensive language is proposed along with a detailed, example-led account of the new typology, an operational definition of implicitly offensive language, and a thorough analysis of the role of figurative language and humour in each type. Our analyses identify three main issues with previous datasets and typologies used in NLP approaches: (a) conflating content and form in the annotation; (b) treating figurativeness, particularly metaphor, as the main device of implicitness, while ignoring its equally important role in the explicit offence; and (c) an over-focus on form-specific datasets (e.g. focusing only on offensive comparisons), which fails to reflect the full complexity of offensive language use. This article could be referential being applied to the filed of sentimental analysis, since sentiments are also subtle, contextual, and plausibly deniable. Through combining context and machine learning, computational analysis and detection mechanism may be more accurate inthe future @Despot2023. 

# Methods

Recalling that the aim of this study is to explore sentimental levels and pronouns of texts in relation to genre, units of observation here will be writings in various genres, and variables needed to explore will be: **sentimental words**, **sentimental level of the word** (Super positive/negative, positive/negative, or neutral), **number of sentimental words contained**, **pronouns** (first, second, or third), **number of pronouns words contained**, and **genre of the text** (fan fiction, novel, letters, email, academic writing, etc.). 
First, data will be pulled from social media and other types of textual corpora database. Then, the pulled texts will first be processed and needed variables will be extracted from the collected texts. Thirdly, subsets of data will be analyzed respectively to examine whether or not its results fit the hypothesis. Lastly, all the data and their correlation will be visualized. 

# Data preparation & Analysis 

**Phase 1: Harvest social media data and compile a corpus**

In this stage, automated tools can be used to query records of social media data, extract this data, and compile it into a corpus @Andreotta2019. Ideally, data from Twitter and Instagram will be collected: [Twitter-API](https://developer.twitter.com/en/docs/twitter-api) and [Facebook/Instagram](https://developers.facebook.com/docs/instagram-api). Also ideally, similar amount of data from roughly the same time interval should be collected from each platform. 

**Phase 2: Categorize and subset variables**

An idealized structure for the topic modeling dataset is seen in @tbl-topic-ideal: 

| variable | name | type | description |
|----------|------|-------------|--|
| post_id | Post ID | integer | Unique identifier for each post |
| post_year | Post Year | integer | Year of the Post |
| type | Word type | character | Individual words from the `text` variable |
| frequency | Frequency | integer | Frequency of the word type in the `text` variable |

: Idealized structure for the topic modeling dataset {#tbl-topic-ideal tbl-colwidths="[15, 15, 15, 55]"}

First, all the extracted data will be given a unique identifier and the date, the year, the post is published will also be recorded. Then, using the method of sentiment analysis, we tokenize all the text and filter all the variables that are necessary need for this project to reduce some complexity. With the `frequency`, content words with highest frequency may also be observed in this project. 

Then, introducing the `bing` lexicon, all the sentiment words will be extracted from the text and classified into the basic categories, using the method of sentiment analysis. The average level of sentiments in each platform will be calculated. Each level of sentiments will be assigned a distinct value (*E.g. Super positive/negative-1, positive/negative-0.5, neutral-0*). Now introducing the `left_join()` function, it will be "attach" the `sentiment` column to the original dataset.

**Phase 3: Analyze and visualize**

First, using sum of all the values in each text to divide the total number of sentimental words will be the average strong level of sentimental words in the text, and using this value, the average strong level of words in each platform and words with highest frequency will then be found. Tables representing sentimental level of text in relation of genre can then be drawn.
Similarly, tables that visualize relation between platform and preference in the use of content words. The strong level of sentimental words in each platform will be displayed, which will either prove or falsify the hypothesis.  

# Expected results

Formal academic writing is more likely to use third-person pronouns and neutral level of sentimental words, compared to fan fiction/ If the the text employ more first/second pronouns with the use of strong level of sentimental words, it is likely to be fiction. 

# Communication plan

The intended audience for the study can be anyone who is interested in linguistics, or anyone who wants to explore how genre may influence writers' word choices in the use of pronouns and sentimental words. The results of the study will be presented orally and visually in class, and the html version of the study will be open-source for the public, which audiences may find in github. 

# Conclusion

///

# Appendix {.appendix}

This section includes any additional information that is relevant to the prospectus, such as data sources, code, or other supplementary materials (Doesn't have anything to add yet).
